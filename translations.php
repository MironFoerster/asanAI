<?php
	$GLOBALS['translations'] = array(
		'en' => array(
			'lets_suppose_we_have_this_simple_network' => 'We want to use this neural network to train a model..',
			'we_want_to_train_this_model_5_categories' => 'The model should learn to classify images correctly into one of these 5 categories:',
			'fire' => 'Fire prevention',
			'mandatory' => 'Mandatory',
			'forbidden' => 'Forbidden',
			'rescue' => 'Rescue',
			'warning' => 'Warning',
			'the_more_variations_the_model_sees' => 'The more variations the model sees, the better it can learn important features of the images.',
			'quality_depends_on_random' => 'The quality of the results depends on randomness.',
			'program_looks_at_data' => 'The program now looks at the data repeatedly and tries to learn to categorize the images.',
			'the_further_on_top_the_better' => 'The more images are correctly in the to the top blue area, the better the network learned.',
			'add_category' => 'Add category',
			'settings' => 'Settings',
			'description' => 'Description',
			'use_bias' => 'Use Bias',
			'activation_function' => 'Activation function',
			'bias_initializer' => 'Bias-Initializer',
			'kernel_initializer' => 'Kernel-Initializer',
			'trainable' => 'Trainable',
			'visualize_layer' => 'Visualize layer',
			'visualize_this_layer' => 'Visualize this layer',
			'examples' => 'Examples',
			'dataset' => 'Dataset',
			'height' => 'Height',
			'width' => 'Width',
			'batch_size' => 'Batch-Size',
			'epochs' => 'Epochs',
			'own_data' => 'Data Source',
			'filters' => 'Filters',
			'distribution' => 'Distribution',
			'image_options' => 'Image Options',
			'feature_extraction' => 'Feature ex&shy;traction',
			'classification' => 'Classi&shy;fication',
			'flatten' => 'Flatten',
			'dataset_and_network' => 'Dataset and network',
			'model_visualization' => 'Model Visualization',
			'data' => 'Data',
			'currently_the_network_has_seen' => 'Currently, the network has seen all data',
			'of' => 'of',
			'times_seen' => 'times.',
			'it_will_take_about' => 'It will take about',
			'remain_left' => ' ',
			'camera_draw_self' => 'Camera/draw',
			'click_on' => 'Click on',
			'if_bad_continue_training' => 'If the results are still bad, continue training.',
			'the_ai_thinks_categories_look_like_this' => 'A visual representation of what the AI has learnt',
			'it_might_only_be_noise' => 'Thats why you are probably only seeing random noise and the detection may not work properly yet.',
			'image_left' => 'image left',
			'images_left' => 'images left',
			'beginner' => 'Beginner',
			'expert' => 'Expert',
			'except_last_layer' => 'except last layer',
			'activation_functions' => 'Activation functions',
			'set_for_all_layers' => 'Set for all layers',
			'shuffle_before_each_epoch' => 'Shuffle before each epoch',
			'summary' => 'Summary',
			'own_images' => 'Own images',
			'own_tensors' => 'Own tensors',
			'kernel_size' => 'Kernel-Size',
			'start_training' => 'Start training',
			'stop_training' => 'Stop training',
			'imprint' => 'Imprint',
			'change_shape' => 'Change shape',
			'simulate_real_data' => 'Simulate real data',
			'dimensionality_reduction' => 'Di&shy;men&shy;sio&shy;na&shy;lity re&shy;duc&shy;tion',
			'shy_activation_function' => 'Ac&shy;ti&shy;va&shy;tion fun&shy;ction',
			'shy_overfitting_prevention' => 'Pre&shy;vent Over&shy;fit&shy;ting',
			'rescale_and_recenter' => 'Re-scale and re-center data',
			'show_layer_data_flow' => 'Show layer data flow',
			'show_grad_cam' => 'Show gradCAM',
			'code' => 'Code',
			'own_csv' => 'Own CSV',
			'training' => 'Training',
			'predict' => 'Predict',
			'hyperparameters' => 'Hyperparameters',
			'valsplit' => 'Val.-Split',
			'divide_x_by' => 'Divide <i>X</i> by',
			'metric' => 'Metric',
			'loss' => 'Loss',
			'optimizer' => 'Optimizer',
			'learning_rate' => 'Learning Rate',
			'enable_tf_debug' => 'Enable TFJS Debugger',
			'enable_webcam' => 'Enable webcam',
			'switch_to_other_cam' => 'Switch to other cam',
			'copy_to_clipboard' => 'Copy to clipboard',
			'set_all_initializers' => 'Set all Initializers',
			'augmentation' => 'Augmentation',
			'iterations' => 'Iterations',
			'close' => 'Close',
			'register' => 'Register',
			'csv' => 'CSV',
			'math' => 'Math',
			'smaller' => 'Smaller',
			'larger' => 'Larger',
			'reset' => 'Reset',
			'delete_predictions' => 'Delete predictions',
			'memory_usage_while_training' => 'Memory usage while training (per batch)',
			'img_per_cat' => 'Img/cat',
			'batches' => 'Batches',
			'login' => 'Login',
			'username' => 'Username',
			'password' => 'Password',
			'download' => 'Download',
			'email' => 'E-Mail',
			'public' => 'Public',
			'save' => 'Save',
			'augment' => 'Augment',
			'download_model_data' => 'Download model data',
			'logout' => 'Logout',
			'load' => 'Load',
			'download_for_local_taurus' => 'Download for local/taurus training',
			'max_activated_neurons' => 'Max. activated neurons',
			'no_default_data' => 'Default data',
			'yes_own_tensor_data' => '&#x2318; Own tensor-data',
			'yes_own_csv' => '&#128290; Own CSV',
			'yes_own_images' => '&#128444; Own images/webcam',
			'width_amp_height' => 'Width&amp;height (0 = auto)',
			'randomizer_limits' => 'Randomizer Limits',
			'max_neurons_fcnn' => 'Max. neurons FCNN',
			'various_plots' => 'Various Plots',
			'sources_and_used_programs' => 'Sources and used programs',
			'visualize_images_in_grid' => 'Visualize images in grid',
			'model_compiled_successfully' => 'Model compiled successfully',
			'not_creating_model_because_values_are_missing' => 'Not creating model because some values are missing',
			'tensors' => 'Tensors',
			'set_val_split_to' => 'Set validationSplit to ',
			'set_optimizer_to' => 'Setting optimizer to ',
			'set_metric_to' => 'Setting metric to ',
			'set_loss_to' => 'Setting loss to ',
			'show_bars_instead_of_numbers' => 'Show bars instead of numbers',
			'number_of_grid_images' => 'Number of grid images',
			'show_raw_data' => 'Show raw data',
			'pixel_size' => 'Pixel size',
			'auto_rotate_images' => 'Auto rotate images',
			'number_of_rotations' => 'Number of rotations',
			'pretext_prepare_data' => 'You must prepare your dataset yourself! You can use this piece of code to generate the data file in the correct format after you pre-processed them.',
			'reset_view' => 'Reset view',
			'reinitialize_weights' => 'Reinitialize weights',
			'show_input_layer' => 'Show Input-Layer',
			'batch_plot_minimum_time' => 'Batch-Plot-Minimum-Time',
			'loss_metric_data_and_shape' => 'Loss, Metric, Data and Shapes',
			'sine_ripple' => 'Sine-Ripple',
			'invert_images' => 'Invert images',
			'flip_left_right' => 'Flip left and right',
			'layer_data_flow' => 'Layer data flow',
			'dense_description' => 'Creates a dense (fully connected) layer.<br>This layer implements the operation: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>output</mtext> <mo>=</mo> <mtext>activation</mtext><mo>(</mo><mtext>input</mtext> <mo>&#8290; &#8901;</mo> <mtext>kernel</mtext> <mo>+</mo> <mtext>bias</mtext><mo>)</mo></mrow></math> activation is the element-wise activation function passed as the activation argument.<br><tt>kernel</tt> is a weights matrix created by the layer.<br><tt>bias</tt> is a bias vector created by the layer (only applicable if useBias is true).',
			'flatten_description' => 'Flattens the input. Does not affect the batch size. A Flatten layer flattens each batch in its inputs to 1D (making the output 2D).',
			'dropout_description' => 'Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.',
			'reshape_description' => 'Reshapes an input to a certain shape.',
			'elu_description' => 'Exponential Linear Unit (ELU).<br>It follows: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>ELU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>&#945;</mi><mo>&#8290; &#8901;</mo><mo>(</mo><mi>e</mi><sup><mi>x</mi></sup><mo>&#8290; &#8901;</mo><mo>-</mo><mn>1</mn><mo>)</mo></mtd><mtd><mi>for</mi></mtd><mtd><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>x</mi></mtd><mtd><mi>for</mi></mtd><mtd><mi>x</mi><mo>&#8805;</mo><mn>0</mn></mtd></mtr></mtable><mo>}</mo></math>',
			'leakyReLU_description' => 'Leaky version of a rectified linear unit.<br>It allows a small gradient when the unit is not active: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>LeakyReLU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>&#945;</mi><mo>&#8290; &#8901;</mo><mi>x</mi></mtd><mtd><mi>for</mi></mtd><mtd><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>x</mi></mtd><mtd><mi>for</mi></mtd><mtd><mi>x</mi><mo>&#8805;</mo><mn>0</mn></mtd></mtr></mtable><mo>}</mo></math>',
			'reLU_description' => 'Rectified Linear Unit activation function. <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>ReLU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>max</mo><mo>(</mo><mn>0</mn><mo>,</mo><mi>x</mi><mo>)</mo></math>',
			'softmax_description' => 'Softmax activation layer. <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>softmax</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi>e</mi><sup><mi>z</mi><sub>j</sub></sup></mrow><mrow><mo>&#8721;</mo><munderover><mo>&#8722;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>e</mi><sup><mi>z</mi><sub>k</sub></sup></mrow></mfrac></math>',
			'thresholdedReLU_description' => 'Thresholded Rectified Linear Unit. It follows: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>x</mi></mtd><mtd><mi>for</mi></mtd><mtd><mi>x</mi><mo>&gt;</mo><mi>&#952;</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>otherwise</mi></mtd></mtr></mtable><mo>}</mo></math>',
			'batchNormalization_description' => "Batch normalization layer (<a href='https://arxiv.org/abs/1502.03167' target='_blank'>Ioffe and Szegedy, 2014</a>).<br>Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.",
			'layerNormalization_description' => "Layer-normalization layer (<a target='_blank' href='https://arxiv.org/abs/1607.06450'>Ba et al., 2016</a>). Normalizes the activations of the previous layer for each given example in a batch independently, instead of across a batch like in batchNormalization. In other words, this layer applies a transformation that maintanis the mean activation within each example close to 0 and activation variance close to 1.",
			'conv1d_description' => '1D convolution layer (e.g., temporal convolution).<br>This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs.<br>If <tt>use_bias</tt> is True, a bias vector is created and added to the outputs.<br>If <tt>activation</tt> is not <tt>null</tt>, it is applied to the outputs as well.',
			'conv2d_description' => '2D convolution layer (e.g. spatial convolution over images).<br>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.<br>If <tt>useBias</tt> is True, a bias vector is created and added to the outputs.<br>If <tt>activation</tt> is not null, it is applied to the outputs as well.',
			'conv2dTranspose_description' => 'Transposed convolutional layer (sometimes called Deconvolution). The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.',
			'conv3d_description' => '3D convolution layer (e.g. spatial convolution over volumes).<br>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.',
			'depthwiseConv2d_description' => 'Depthwise separable 2D convolution. Depthwise Separable convolutions consists in performing just the first step in a depthwise spatial convolution (which acts on each input channel separately). The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'separableConv2d_description' => 'Depthwise separable 2D convolution. Separable convolution consists of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'upSampling2d_description' => 'Upsampling layer for 2D inputs. Repeats the rows and columns of the data by size[0] and size[1] respectively.',
			'averagePooling1d_description' => 'Average pooling operation for spatial data.',
			'averagePooling2d_description' => 'Average pooling operation for spatial data.',
			'maxPooling1d_description' => 'Max pooling operation for temporal data.',
			'maxPooling2d_description' => 'Global max pooling operation for spatial data.',
			'alphaDropout_description' => 'Applies Alpha Dropout to the input. As it is a regularization layer, it is only active at training time.',
			'gaussianDropout_description' => 'Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'gaussianNoise_description' => 'Apply additive zero-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'DebugLayer_description' => "Log internal state of the data to the developer's console. Does nothing to the data itself.",
			'max_number_of_values' => 'Max number of values (0 = no limit)',
			'provide_x_data' => 'Provide X-data file',
			'provide_y_data' => 'Provide Y-data file',
			'download_custom_zip_file' => 'Download custom data in a .zip file',
			'delay_between_images' => 'Delay in seconds between images in a series',
			'number_of_images_in_series' => 'Number of images in a series',
			'restart_fcnn' => "Restart FCNN",
			'restart_alexnet' => 'Restart AlexNet',
			'restart_lenet' => 'Restart LeNet',
			'undo_redo_stack_lost' => 'Undo/redo stack lost!',
			'changing_mode_deletes_stack' => 'Changing the mode deletes the undo/redo stack.',
			'auto_adjust_last_layer_if_dense' => "Auto-adjust last layer's number of neurons (if Dense)",
			'load_images' => 'Load Images',
			"loading_data" => 'Loading data',
			'ai_tries_to_draw' => 'The AI tries to draw how it thinks the categories look like...',
			'stop_generating_images' => 'Stop generating images',
			'stopped_generating_images' => "Stopped generating new images, this may take a while",
			'now_being' => 'Now, ',
			'images_of_each_category' => 'Images of each categories are being loaded.',
			'one_second' => "one second",
			'years' => 'years',
			'year' => 'year',
			'minutes' => 'minutes',
			'minute' => 'minute',
			'seconds' => 'seconds',
			"hours" => "hours",
			'second' => 'second',
			'days' => 'days',
			'day' => 'day',
			'left' => 'left',
			"example_images" => "Example Images",
			"and_try_to_draw_a_warning_sign" => "and try to draw a warning sign",
			"go_back_to_examples" => "to go back to example images",
			'the_training_was_only_with' => 'The training has been done with only',
			'images_and' => 'images and',
			'epochs_done' => 'epochs done. Thus, the results are probably bad',
			'this_may_take_a_while' => 'This may take a while',
			"loading_images_into_memory" => "Loading images into memory",
			"train_the_neural_network" => "Tap here to train neural network",
			"train_further" => "Train the network further",
			"loading_model" => "Loading model",
			"loading_example_images" => "Loading example images",
			"undoing_redoing" => "Undoing/redoing",
			"skip_presentation" => "Skip &rarr;",
			"very_unsure" => "Very unsure",
			"quite_unsure" => "Quite unsure",
			"a_bit_unsure" => "A bit unsure",
			"neutral" => "A bit sure",
			"relatively_sure" => "Relatively sure",
			"very_sure" => "Very sure",
			"time_per_batch" => "Time per Batch",
			"training" => "Training",
			"done_training_took" => "Done Training, took",
			"done_generating_images" => "Done generating images",
			"generating_image_for_neuron" => "Generating image for neuron",
			"failed_try_again" => "failed. Trying again",
			"fixing_output_shape" => "Output shape is being fixed...",
			"output_shape_repaired" => "Output shape repaired",
			"please_try_training_again" => 'Please try training again',
			'No' => 'No',
			'Yes' => 'Yes',
			'autofix_output_shape' => 'Do you want to automatically fix the output shape?',
			'defective_output_shape' => 'Defective output shape detected',
			"switched_to_beginner_mode" => "Switched to beginner mode",
			"beginner" => "Beginner",
			"expert" => "Expert",
			'changed_mode_from' => "Changed mode from",
			"to" => "to",
			"lost_undo_redo_stack" => "lost undo/redo stack",
			"stopped_training" => "Stopped training",
			"allow_math_mode_for_all_layers" => "Allow math mode for all layers",
			"updating_predictions" => "Updating predictions",
			"loaded_configuration" => "Loaded configuration",
			"model_is_not_defined" => "Model is not defined",
			"model_is_ok" => "Model is OK",
			"got_data" => "Got data",
			"site_is_ready" => "Site is ready",
			"trying_to_set_backend" => "Trying to set backend",
			"backend_set" => "Backend set",
			"set_theme" => "Set theme",
			"theme_set" => "Theme set",
			"has_cookie_for" => "Has cookie for",
			"initializing_losses" => "Initializing losses",
			"initializing_metrics" => "Initializing metrics",
			"setting_backend" => "Setting backend",
			"width" => "width",
			"height" => "height",
			"changing" => "Changing",
			"changed_data_source" => "Changed data source",
			"hiding_augmentation" => "Hiding augmentation",
			"showing_augmentation" => "Showing augmentation",
			"input_shape_is_read_only" => "The Input-Shape read-only",
			"input_shape_is_writable" => "The Input-Shape is editable",
			"updating_page" => "Updating page...",
			"page_update_took" => "Page update took",
			"getting_labels" => "Getting labels",
			"compiling_model" => "Compiling model",
			"done_changing" => "Done changing",
			"took" => "took",
			"setting_layer" => "Setting layer",
			"setting_options_for_layer" => "Setting options for layer",
			"creating_model" => "Creating model",
			"graph_explanation" => "The lines in the graph represent the error. The lower the line, the smaller the error. The blue line indicates the improvements on the data that the network is trained on, while the orange line indicates how well it performs on data it hasn't seen before. Both lines should decrease and look somewhat similar for the training to be progressing well.",
			"previous_images" => "Previous images",
			"current_images" => "Current images"
		),
		'de' => array(
			'lets_suppose_we_have_this_simple_network' => 'Wir möchten dieses Bilderkennungsnetzwerk verwenden, um ein Modell zu trainieren.',
			'we_want_to_train_this_model_5_categories' => 'Das Modell soll lernen, um 5 Kategorien von Symbolen zu unterscheiden:',
			'fire' => 'Brandschutz',
			'mandatory' => 'Gebot',
			'forbidden' => 'Verbot',
			'rescue' => 'Rettung',
			'warning' => 'Warnung',
			'the_more_variations_the_model_sees' => 'Je mehr Variationen das Modell sieht, desto besser kann es die wichtigsten Merkmale der Bilder lernen.',
			'quality_depends_on_random' => 'Die Qualität des Ergebnisses hängt vom Zufall ab.',
			'program_looks_at_data' => 'Das Programm schaut sich jetzt alle diese Bilder immer wieder an und versucht zu lernen, sie zu kategorisieren.',
			'the_further_on_top_the_better' => 'Umso mehr Bilder im oberen, blauen Bereich richtig eingeordnet sind, desto besser hat das Netzwerk gelernt.',
			'add_category' => 'Kategorie hinzufügen',
			'settings' => 'Einstellungen',
			'description' => 'Be&shy;schrei&shy;bung',
			'use_bias' => 'Bias benutzen',
			'activation_function' => 'Aktivier&shy;ungs&shy;fun&shy;ktion',
			'bias_initializer' => 'Bias-Initialisierer',
			'kernel_initializer' => 'Kernel-Initialisierer',
			'trainable' => 'Trainierbar',
			'visualize_layer' => 'Layer visualisieren',
			'visualize_this_layer' => 'Diesen Layer visualisieren',
			'examples' => 'Beispiele',
			'dataset' => 'Datensatz',
			'height' => 'Höhe',
			'width' => 'Breite',
			'batch_size' => 'Batchgröße',
			'epochs' => 'Epochen',
			'own_data' => 'Datenquelle',
			'filters' => 'Filter',
			'distribution' => 'Verteilung',
			'image_options' => 'Bildoptionen',
			'feature_extraction' => 'Merkmalsex&shy;traktion',
			'classification' => 'Klassi&shy;fikation',
			'flatten' => 'Verflachen',
			'dataset_and_network' => 'Datensatz und Netzwerk',
			'model_visualization' => 'Modellvisualisierung',
			'data' => 'Daten',
			'currently_the_network_has_seen' => 'Aktuell hat sich die Software alle Daten',
			'of' => 'von',
			'times_seen' => 'mal angesehen',
			'it_will_take_about' => 'Es wird noch ca.',
			'remain_left' => 'dauern',
			'camera_draw_self' => 'Kamera/selbstmalen',
			'click_on' => 'Klicke auf',
			'if_bad_continue_training' => 'Wenn die Ergebnisse noch zu schlecht sind, trainiere weiter.',
			'the_ai_thinks_categories_look_like_this' => 'Eine visuelle Repräsentation dessen, was die KI gelernt hat',
			'it_might_only_be_noise' => 'Daher siehst du hier wahrscheinlich nur Rauschen und die Erkennung geht noch nicht.',
			'image_left' => 'Bild übrig',
			'images_left' => 'Bilder übrig',
			'beginner' => 'Anfänger',
			'expert' => 'Experte',
			'except_last_layer' => 'außer letztem Layer',
			'activation_functions' => 'Aktivierungsfunktionen',
			'set_for_all_layers' => 'Einstellungen für alle Layer',
			'shuffle_before_each_epoch' => 'Vor jeder Epoche zufällig sortieren',
			'summary' => 'Zusammenfassung',
			'own_images' => 'Eigene Bilder',
			'own_tensors' => 'Eigene Tensoren',
			'kernel_size' => 'Kernel-Größe',
			'start_training' => 'Training starten',
			'stop_training' => 'Training stoppen',
			'imprint' => 'Impressum',
			'change_shape' => 'Shape verändern',
			'simulate_real_data' => 'Echten Daten simulieren',
			'dimensionality_reduction' => 'Di&shy;men&shy;sio&shy;ns&shy;re&shy;duk&shy;tion',
			'shy_activation_function' => 'Ak&shy;ti&shy;vier&shy;ungsfun&shy;ktion',
			'shy_overfitting_prevention' => 'Over&shy;fit&shy;ting ver&shy;hinderung',
			'rescale_and_recenter' => 'Reskalierung und Zentrierung',
			'show_layer_data_flow' => 'Datenfluss anzeigen',
			'show_grad_cam' => 'gradCAM anzeigen',
			'code' => 'Quellcode',
			'own_csv' => 'Eigene CSV',
			'training' => 'Training',
			'predict' => 'Predict',
			'hyperparameters' => 'Hyperparameter',
			'valsplit' => 'Val.-Split',
			'divide_x_by' => 'Teile <i>X</i> durch',
			'metric' => 'Metrik',
			'loss' => 'Loss',
			'optimizer' => 'Optimierer',
			'learning_rate' => 'Lernrate',
			'enable_tf_debug' => 'TFJS Debugger aktivieren',
			'enable_webcam' => 'Webcam aktivieren',
			'switch_to_other_cam' => 'Zur anderen Kamera wechseln',
			'copy_to_clipboard' => 'In Zwischenablage kopieren',
			'set_all_initializers' => 'Setze alle Initialisierer',
			'augmentation' => 'Augmentierung',
			'iterations' => 'Iterationen',
			'close' => 'Schließen',
			'register' => 'Registrieren',
			'csv' => 'CSV',
			'math' => 'Mathe',
			'smaller' => 'Kleiner',
			'larger' => 'Größer',
			'reset' => 'Reset',
			'delete_predictions' => 'Predictions löschen',
			'memory_usage_while_training' => 'Speicherverbrauch während des Trainings (pro Batch)',
			'img_per_cat' => 'Bilder/Kat.',
			'batches' => 'Batches',
			'login' => 'Anmelden',
			'username' => 'Benutzername',
			'password' => 'Passwort',
			'download' => 'Herunterladen',
			'email' => 'E-Mail',
			'public' => 'Öffentlich',
			'save' => 'Speichern',
			'augment' => 'Augmentieren',
			'download_model_data' => 'Modelldaten downloaden',
			'logout' => 'Abmelden',
			'load' => 'laden',
			'download_for_local_taurus' => 'Für lokales oder Taurus-Training herunterladen',
			'max_activated_neurons' => 'Maximal aktivierte Neuronen',
			'no_default_data' => 'Standarddaten',
			'yes_own_tensor_data' => '&#x2318; eigene Tensordaten',
			'yes_own_csv' => '&#128290; eigene CSV',
			'yes_own_images' => '&#128444; eigene Bilder/Webcam',
			'width_amp_height' => 'Höhe&amp;Breite (0 = auto)',
			'randomizer_limits' => 'Randomisierergrenzen',
			'max_neurons_fcnn' => 'Max. Neuronen FCNN',
			'various_plots' => 'Verschiedene Plots',
			'sources_and_used_programs' => 'Quellen',
			'visualize_images_in_grid' => 'Bilder in Grid visualisieren',
			'model_compiled_successfully' => 'Modell erfolgreich kompiliert',
			'not_creating_model_because_values_are_missing' => 'Kann Modell nicht erstellen, weil Werte fehlen',
			'tensors' => 'Tensoren',
			'set_val_split_to' => 'Setze den Validation-Split auf ',
			'set_optimizer_to' => 'Setze den Optimierer auf ',
			'set_metric_to' => 'Setze die Metrik auf ',
			'set_loss_to' => 'Setze den Loss auf ',
			'show_bars_instead_of_numbers' => 'Balken statt Zahlen verwenden',
			'number_of_grid_images' => 'Anzahl Bilder im Grid',
			'show_raw_data' => 'Rohdaten anzeigen',
			'pixel_size' => 'Pixelgröße',
			'auto_rotate_images' => 'Bilder automatisch rotieren',
			'number_of_rotations' => 'Anzahl Rotationen',
			'pretext_prepare_data' => 'Du musst deine Daten selbst vorbereiten! Du kannst folgenden Code nehmen, um Datenstrukturen aus Python in das richtige Format umzuwandeln, das du mit asanAI benutzen kannst.',
			'reset_view' => 'Ansicht zurücksetzen',
			'reinitialize_weights' => 'Gewichte reinitialisieren',
			'show_input_layer' => 'Input-Layer anzeigen',
			'batch_plot_minimum_time' => 'Minimale Zeit zwischen Batch-Plots',
			'loss_metric_data_and_shape' => 'Loss, Metrik, Daten und Shapes',
			'sine_ripple' => 'Sinus-Kräusel',
			'invert_images' => 'Bilder invertieren',
			'flip_left_right' => 'Bilder spiegeln',
			'layer_data_flow' => 'Layer-Datenfluss',
			'dense_description' => 'Erstellt eine dichte (vollständig verbundene) Schicht.<br>Diese Schicht implementiert die Operation: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mtext>output</mtext> <mo>=</mo> <mtext>activation</mtext><mo>(</mo><mtext>input</mtext> <mo>&#8290; &#8901;</mo> <mtext>kernel</mtext> <mo>+</mo> <mtext>bias</mtext><mo>)</mo></mrow></math> Die Aktivierung ist die elementweise Aktivierungsfunktion, die als Aktivierungsargument übergeben wird.<br><tt>kernel</tt> ist eine Gewichtsmatrix, die von der Schicht erstellt wird.<br><tt>bis</tt> ist ein Bias-Vektor, der von der Schicht erstellt wird (nur anwendbar, wenn useBias true ist).',
			'flatten_description' => 'Flacht die Eingabe ab. Beeinflusst nicht die Batch-Größe. Eine Flatten-Schicht macht in ihren Eingaben jede Batch in 1D flach (wodurch die Ausgabe 2D wird).',
			'dropout_description' => 'Dropout besteht darin, eine Bruchteilrate der Eingabeeinheiten während jeder Aktualisierung während der Trainingszeit zufällig auf 0 zu setzen, was Überanpassung verhindert.',
			'reshape_description' => 'Formt eine Eingabe in eine bestimmte Form um.',
			'elu_description' => 'Exponential Linear Unit (ELU).<br>Es folgt: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>ELU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>&#945;</mi><mo>&#8290; &#8901;</mo><mo>(</mo><mi>e</mi><sup><mi>x</mi></sup><mo>&#8290; &#8901;</mo><mo>-</mo><mn>1</mn><mo>)</mo></mtd><mtd><mi>für</mi></mtd><mtd><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>x</mi></mtd><mtd><mi>für</mi></mtd><mtd><mi>x</mi><mo>&#8805;</mo><mn>0</mn></mtd></mtr></mtable><mo>}</mo></math>',
			'leakyReLU_description' => 'Leaky-Version einer rektifizierten linearen Einheit.<br>Sie erlaubt eine kleine Steigung, wenn die Einheit nicht aktiv ist: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>LeakyReLU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>&#945;</mi><mo>&#8290; &#8901;</mo><mi>x</mi></mtd><mtd><mi>für</mi></mtd><mtd><mi>x</mi><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mi>x</mi></mtd><mtd><mi>für</mi></mtd><mtd><mi>x</mi><mo>&#8805;</mo><mn>0</mn></mtd></mtr></mtable><mo>}</mo></math>',
			'reLU_description' => 'Aktivierungsfunktion der rektifizierten linearen Einheit. <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>ReLU</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>max</mo><mo>(</mo><mn>0</mn><mo>,</mo><mi>x</mi><mo>)</mo></math>',
			'softmax_description' => 'Softmax-Aktivierungsschicht. <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mo>softmax</mo><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mfrac><mrow><mi>e</mi><sup><mi>z</mi><sub>j</sub></sup></mrow><mrow><mo>&#8721;</mo><munderover><mo>&#8722;</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>e</mi><sup><mi>z</mi><sub>k</sub></sup></mrow></mfrac></math>',
			'thresholdedReLU_description' => 'Thresholded Rectified Linear Unit. Es folgt: <math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mi>x</mi></mtd><mtd><mi>für</mi></mtd><mtd><mi>x</mi><mo>&gt;</mo><mi>&#952;</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mi>sonst</mi></mtd></mtr></mtable><mo>}</mo></math>',
			'batchNormalization_description' => "Batch-Normalisierungsschicht (<a href='https://arxiv.org/abs/1502.03167' target='_blank'>Ioffe and Szegedy, 2014</a>).<br>Normalisieren Sie die Aktivierungen der vorherigen Schicht in jeder Batch, d.h. wendet eine Transformation an, die die mittlere Aktivierung nahe bei 0 und die Aktivierungsstandardabweichung nahe bei 1 hält.",
			'layerNormalization_description' => "Schicht-Normalisierungsschicht (<a target='_blank' href='https://arxiv.org/abs/1607.06450'>Ba et al., 2016</a>). Normalisieren Sie die Aktivierungen der vorherigen Schicht für jedes gegebene Beispiel in einer Batch unabhängig voneinander, anstatt in einer Batch wie in der Batch-Normalisierung. Mit anderen Worten, diese Schicht wendet eine Transformation an, die die mittlere Aktivierung innerhalb jedes Beispiels nahe bei 0 und die Aktivierungsvarianz nahe bei 1 hält.",
			'conv1d_description' => '1D-Faltungs-Schicht (z.B. zeitliche Faltung).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht über eine einzelne räumliche (oder zeitliche) Dimension gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.<br>Wenn <tt>use_bias</tt> True ist, wird ein Bias-Vektor erstellt und den Ausgaben hinzugefügt.<br>Wenn <tt>activation</tt> nicht <tt>null</tt> ist, wird es auch auf die Ausgaben angewendet.',
			'conv2d_description' => '2D-Faltungs-Schicht (z.B. räumliche Faltung über Bilder).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.<br>Wenn <tt>useBias</tt> True ist, wird ein Bias-Vektor erstellt und den Ausgaben hinzugefügt.<br>Wenn <tt>activation</tt> nicht null ist, wird es auch auf die Ausgaben angewendet.',
			'conv2dTranspose_description' => 'Transponierte Faltungsschicht (manchmal auch Deconvolution genannt). Der Bedarf an transponierten Faltungen ergibt sich in der Regel aus dem Wunsch, eine Transformation in die entgegengesetzte Richtung einer normalen Faltung zu verwenden, d.h. von etwas, das die Form der Ausgabe einiger Faltungen hat, zu etwas, das die Form ihres Eingangs hat, während ein Konnektivitätsmuster beibehalten wird, das mit dieser Faltung kompatibel ist.',
			'conv3d_description' => '3D-Faltungs-Schicht (z.B. räumliche Faltung über Volumen).<br>Diese Schicht erstellt einen Faltungskern, der mit der Eingabe der Schicht gefaltet wird, um einen Tensor von Ausgaben zu erzeugen.',
			'depthwiseConv2d_description' => 'Depthwise separable 2D convolution. Depthwise Separable convolutions consists in performing just the first step in a depthwise spatial convolution (which acts on each input channel separately). The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'separableConv2d_description' => 'Depthwise separable 2D convolution. Separable convolution consists of first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.',
			'upSampling2d_description' => 'Upsampling layer for 2D inputs. Repeats the rows and columns of the data by size[0] and size[1] respectively.',
			'averagePooling1d_description' => 'Average pooling operation for spatial data.',
			'averagePooling2d_description' => 'Average pooling operation for spatial data.',
			'maxPooling1d_description' => 'Max pooling operation for temporal data.',
			'maxPooling2d_description' => 'Global max pooling operation for spatial data.',
			'alphaDropout_description' => 'Applies Alpha Dropout to the input. As it is a regularization layer, it is only active at training',
			'gaussianDropout_description' => 'Apply multiplicative 1-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'gaussianNoise_description' => 'Apply additive zero-centered Gaussian noise. As it is a regularization layer, it is only active at training time.',
			'DebugLayer_description' => 'Protokolliert den internen Zustand der Daten in die Entwicklerkonsole. Tut nichts mit den Daten selbst.',
			'max_number_of_values' => 'Maximale Anzahl an Werten (0 = kein Limit)',
			'provide_x_data' => 'X-Daten',
			'provide_y_data' => 'Y-Daten',
			'download_custom_zip_file' => 'Downloade die eigenen Daten als .zip-Datei',
			'delay_between_images' => 'Wartezeit zwischen den Bildern in der Serie',
			'number_of_images_in_series' => 'Anzahl Bilder pro Serie',
			'restart_fcnn' => "FCNN neustarten",
			'restart_alexnet' => 'AlexNet neustarten',
			'restart_lenet' => 'LeNet neustarten',
			'undo_redo_stack_lost' => 'Rückgängig/wiederherstellen-Stack verloren!',
			'changing_mode_deletes_stack' => 'Das ändern des Modus löscht den gesamten Undo/Redo-Stack.',
			'auto_adjust_last_layer_if_dense' => "Automatisch den letzten Layer anpassen (wenn Dense)",
			'load_images' => 'Lade Bilder',
			"loading_data" => 'Lade Daten',
			'ai_tries_to_draw' => 'Die KI versucht zu malen, wie sie diese Kategorien gelernt hat...',
			'stop_generating_images' => 'Bildgenerierung stoppen',
			'stopped_generating_images' => "Die Bildgenerierung wurde gestoppt. Das kann einen Moment dauern.",
			'now_being' => 'Jetzt werden',
			'images_of_each_category' => 'Bilder aus jeder Kategorie geladen.',
			'one_second' => "Eine Sekunde",
			'years' => 'Jahre',
			'year' => 'Jahr',
			'minutes' => 'Minuten',
			'minute' => 'Minute',
			'seconds' => 'Sekunden',
			"hours" => "Stunden",
			'second' => 'Sekunde',
			'days' => 'Tage',
			'day' => 'Tag',
			'left' => 'übrig',
			"example_images" => "Beispielbilder",
			"and_try_to_draw_a_warning_sign" => "und versuche ein Warnschild zu malen",
			"go_back_to_examples" => "um zu den Beispielbildern zurückzugehen",
			'the_training_was_only_with' => 'Das Training wurde mit insgesamt nur',
			'images_and' => 'Bildern und',
			'epochs_done' => 'Epochen gemacht. Die Ergebnisse sind also wahrscheinlich schlecht',
			'this_may_take_a_while' => 'Das kann einen Moment dauern',
			"loading_images_into_memory" => "Lade die Bilder in den Speicher",
			"train_the_neural_network" => "Hier klicken, um neuronales Netz zu trainieren",
			"train_further" => "Das Netzwerk weiter trainieren",
			"loading_model" => "Lade Modell",
			"loading_example_images" => "Lade Beispielbilder",
			"undoing_redoing" => "Rückgängig machen/wiederherstellen",
			"skip_presentation" => "Überspringen &rarr;",
			"very_unsure" => "Sehr unsicher",
			"quite_unsure" => "Eher unsicher",
			"a_bit_unsure" => "Ein wenig unsicher",
			"neutral" => "Ein wenig sicher",
			"relatively_sure" => "Relativ sicher",
			"very_sure" => "Sehr sicher",
			"time_per_batch" => "Zeit pro Batch",
			"training" => "Training",
			"done_training_took" => "Training fertig, es dauerte",
			"done_generating_images" => "Bilder fertig generiert",
			"generating_image_for_neuron" => "Generiere Bild für Neuron",
			"failed_try_again" => "fehlgeschlagen. Versuche es erneut",
			"fixing_output_shape" => "Output-Shape wird repariert",
			"output_shape_repaired" => "Output shape repariert",
			"please_try_training_again" => 'Bitte erneut trainieren',
			'No' => 'Nein',
			'Yes' => 'Ja',
			'autofix_output_shape' => 'Möchtest du die Output-Shape automatisch reparieren lassen?',
			'defective_output_shape' => 'Kaputte Output-Shape entdeckt!',
			"switched_to_beginner_mode" => "In den Anfängermodus gewechselt",
			"beginner" => "Anfänger",
			"expert" => "Experte",
			'changed_mode_from' => "Modus von",
			"to" => "nach",
			"lost_undo_redo_stack" => "Rückgängig/wiederherstellen resettet",
			"stopped_training" => "Training beendet",
			"allow_math_mode_for_all_layers" => "Mathe-Modus für alle Layer erlauben",
			"updating_predictions" => "Aktualisiere Predictions",
			"loaded_configuration" => "Konfiguration geladen",
			"model_is_not_defined" => "Modell ist nicht definiert",
			"model_is_ok" => "Modell ist OK",
			"got_data" => "Daten geholt",
			"site_is_ready" => "Seite fertig geladen",
			"trying_to_set_backend" => "Versuche, das Backend zu setzen",
			"backend_set" => "Backend gesetzt",
			"set_theme" => "Setze Theme",
			"theme_set" => "Theme gesetzt",
			"has_cookie_for" => "Hat Cookie für",
			"initializing_losses" => "Initialisiere Losses",
			"initializing_metrics" => "Initialisiere Metriken",
			"setting_backend" => "Setze Backend",
			"width" => "Breite",
			"height" => "Höhe",
			"changing" => "Ändere",
			"changed_data_source" => "Datenquelle geändert",
			"hiding_augmentation" => "Augmentierung versteckt",
			"showing_augmentation" => "Augmentierung gezeigt",
			"input_shape_is_read_only" => "Die Input-Shape ist nur lesbar",
			"input_shape_is_writable" => "Die Input-Shape ist bearbeitbar",
			"updating_page" => "Update die Seite...",
			"page_update_took" => "Das Seitenupdate brauchte",
			"getting_labels" => "Hole Labels",
			"compiling_model" => "Kompiliere Modell",
			"done_changing" => "Fertig mit Ändern der",
			"took" => "brauchte",
			"setting_layer" => "Setze Layer",
			"setting_options_for_layer" => "Setze Optionen für Layer",
			"creating_model" => "Erstelle Modell",
			"graph_explanation" => "Die Linien im Graphen zeigen den Fehler an. Umso niedriger die Linie, desto geringer der Fehler. Die blaue Linie zeigt die Verbesserungen auf den Daten, auf denen das Netzwerk trainiert, die orange Linie zeigt an, wie gut es es auf Daten ist , die es nicht gesehen hat. Beide Linien sollten niedriger werden und etwa ähnlich aussehen, damit das Training gut läuft.",
			"previous_images" => "Vorherige Bilder",
			"current_images" => "Aktuelle Bilder"
		)
	);

	function checkSubElementsKeys($array) {
		$keys = [];

		foreach ($array as $subArray) {
			if (!is_array($subArray)) {
				die("Sub-element is not an array");
			}

			$subKeys = array_keys($subArray);

			if (empty($keys)) {
				$keys = $subKeys;
			} elseif ($keys !== $subKeys) {
				$missingKeys = array_diff($keys, $subKeys);
				die("Missing key: " . reset($missingKeys));
			}
		}

		return true;
	}

	if(!checkSubElementsKeys($GLOBALS["translations"])) {
	       	die("Sub-elements do not have the same keys");
	}
?>
